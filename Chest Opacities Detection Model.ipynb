{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dc4982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12820\\120490380.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\distribute\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msidecar_evaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Python module for evaluation loop.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# isort: off\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras import layers\n",
    "#import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94bb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for images\n",
    "\n",
    "path_to_images = \"Data/dataset1/known_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57eaac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4108854685.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\SHARIF\\AppData\\Local\\Temp\\ipykernel_8100\\4108854685.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    dataset = keras.utils.image_dataset_from_directory(path_to images, batch_size = 50, image_size = (395,488))\u001b[0m\n\u001b[1;37m                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = keras.utils.image_dataset_from_directory(\n",
    "    path_to images, class_name=[\"normal\",\"sick\"], \n",
    "    batch_size = 32, \n",
    "    image_size = (395,488),\n",
    "validation_split=0.2,\n",
    "subset=\"both\",\n",
    "seed=200,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss=history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(accuracy)+1)\n",
    "plt.plot(epochs,accuracy, \"bo\", label=\"Training Accuracy\")\n",
    "plt.plot(epochs,val_accuracy,\"b\", label =\"Validation Accuracy\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs,accuracy, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs,val_accuracy,\"b\", label =\"Validation loss\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augumentation = keras.Sequential(\n",
    "[keras.layers.RandomFlip(\"horizontal\"),\n",
    "keras.layers.RandomRotation(0.1),\n",
    "keras.layers.RandomZoom(0.2)\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb1a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating shape of the model\n",
    "\n",
    "inputs = keras.Input(shape(395, 488,3))\n",
    "\n",
    "#data augumentation\n",
    "\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "#rescaling\n",
    "x = keras.layers.Rescaling(1.255)(x)\n",
    "\n",
    "#adding convolution layer\n",
    "\n",
    "x=keras.layers.Conv2D(filters=32,kernel_size=3,activation=\"relu\")(inputs)\n",
    "x=keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "x=keras.layers.Conv2D(filters=64,kernel_size=3,activation=\"relu\")(inputs)\n",
    "x=keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "x=keras.layers.Conv2D(filters=128,kernel_size=3,activation=\"relu\")(inputs)\n",
    "x=keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "x=keras.layers.Conv2D(filters=256,kernel_size=3,activation=\"relu\")(inputs)\n",
    "x=keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "x=keras.layers.Conv2D(filters=256,kernel_size=3,activation=\"relu\")(inputs)\n",
    "x=keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "x=keras.layers.Conv2D(filters=256,kernel_size=3,activation=\"relu\")(inputs)\n",
    "x=keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "#Model flattening\n",
    "\n",
    "x=keras.layers. Flatten()(x)\n",
    "\n",
    "x=keras.layers.Dense(activation=\"relu\")(x)\n",
    "\n",
    "#Dropout\n",
    "x= keras.layers.dropout(0.5)(x)\n",
    "\n",
    "#create model output\n",
    "outputs=keras.layers.Dense(filters=1, kernel_size=3,activation=\"sigmond\")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras builds the Neural Network\n",
    "model.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbdf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12653c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"models/chest_opacities_detection_model_V1.keras\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72699039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trains the model to fit the data/features\n",
    "#Number of iterations - epochs\n",
    "history = model.fit(train_dataset, \n",
    "          batch_size=32,\n",
    "          epochs=5, \n",
    "          verbose=1,\n",
    "         validation_data=val_dataset\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the dataset\n",
    "X_train, Y_train = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model = keras.Sequential ()\n",
    "\n",
    "#Adds layers\n",
    "#model.add(keras.layer.Rescaling(1.0/255))\n",
    "#model.add(keras.layers.Conv2D ((),activation=(\"relu\"))\n",
    "#model.add(keras.layers.MaxPool2D(2, 2))\n",
    "#model.add(keras.layers. Dropout(0,0.25))\n",
    "          \n",
    "#flatten the Convolution layer output\n",
    "#model.add(keras.layers.Flatten())\n",
    "#model.add(keras.Layers.Dense(512,activation=\"relu))\n",
    "#model.add(keras.layers.Dense(2, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37783e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924710ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
